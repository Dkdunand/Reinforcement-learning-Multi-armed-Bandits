# Restless Bandits & Robust Exploration: A Theoretical and Experimental Study
# Objectif
Ce projet explore la robustesse des algorithmes de bandits manchots classiques dans un cadre non stationnaire, inspir√© des environnements financiers r√©els. Nous √©tudions les bandits "restless", un cadre o√π les distributions de r√©compense √©voluent avec le temps, contrairement au mod√®le i.i.d. traditionnel.

L‚Äôobjectif est d‚Äô√©valuer comment les politiques d‚Äôexploration-exploitation ‚Äî cruciales pour la prise de d√©cision s√©quentielle ‚Äî se comportent lorsqu‚Äôon les applique hors de leur cadre th√©orique optimal.

 # Contexte
üî¨ Bandits manchots √† bras finis, o√π les r√©compenses sont d√©pendantes temporellement.

 Bas√© sur le cadre pr√©sent√© par Grunewalder & Khaleghi (2019).

Ce type de d√©salignement est analogue √† de nombreux probl√®mes rencontr√©s en finance algorithmique, o√π les rendements sont souvent autocorr√©l√©s et non stationnaires.

# M√©thodologie
Nous appliquons l‚Äôalgorithme UCB1 (Auer et al., 2002), con√ßu pour des environnements i.i.d., √† des donn√©es g√©n√©r√©es par des processus d√©pendants.

L‚Äôobjectif est d‚Äôobserver l‚Äôimpact de cette d√©pendance sur les performances et de d√©terminer si des ajustements sont n√©cessaires.

# Exp√©rimentations :

Comparaison des performances UCB1 sous diff√©rentes intensit√©s de d√©pendance temporelle.

Simulations multiples avec √©chantillonnage contr√¥l√© pour quantifier la d√©gradation des performances.

 Extensions pr√©vues
Si le temps le permet, nous √©tendrons cette √©tude √† :

 Bandits lin√©aires, avec l‚Äôalgorithme LinUCB (Lattimore & Szepesv√°ri, 2020)

 Comparaison avec LinMix-UCB (Khaleghi, 2025), con√ßu pour les environnements non-i.i.d.

 # Pourquoi ce projet est pertinent pour un hedge fund ?
 Exploration-exploitation en environnement incertain = c≈ìur de l‚Äôallocation dynamique d‚Äôactifs.

 Mod√©lisation de la non-stationnarit√© des march√©s : ce projet examine des situations analogues aux changements de r√©gime, effets m√©moire, autocorr√©lation.

 Capacit√© √† √©valuer la robustesse algorithmique, une comp√©tence cl√© en strat√©gie syst√©matique.

 Combinaison de recherche appliqu√©e et d‚Äôimpl√©mentation exp√©rimentale, avec une attention port√©e √† la r√©alit√© op√©rationnelle.

 # R√©f√©rences cl√©s
Auer et al. (2002) ‚Äì Finite-time Analysis of the Multiarmed Bandit Problem

Grunewalder & Khaleghi (2019) ‚Äì Restless Bandits with Temporal Dependencies

Lattimore & Szepesv√°ri (2020) ‚Äì Bandit Algorithms (Ch. 19)

Khaleghi (2025) ‚Äì LinMix-UCB: Bandit Learning with Structured Temporal Dependence




